{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#网站链接：https://www.gouvernement.fr/search/site/automobile\n",
    "#scrapy code设计参考：https://towardsdatascience.com/a-minimalist-end-to-end-scrapy-tutorial-part-i-11e350bcdec0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#初步的尝试,先抓取所有法国政府网站中以'automobile\"搜索到的页面的标题，url链接和摘要\n",
    "\n",
    "import scrapy\n",
    "\n",
    "class EVSpider(scrapy.Spider):\n",
    "    name = 'Matignon_keyword_automobile'\n",
    "    allowed_domains = [\"www.gouvernement.fr\"]\n",
    "    start_urls = ['https://www.gouvernement.fr/search/site/automobile']\n",
    "    \n",
    "    def parse(self,response):\n",
    "        titles = response.css('h2.node-titre')\n",
    "        for title in titles:\n",
    "            yield {\n",
    "                'title': title.css('h2.node-titre a::text').get(),\n",
    "                'link': title.css('h2.node-titre a::attr(href)').get(),\n",
    "                'teaser': title.css(' p.teaser-intro::text').get(),\n",
    "            }\n",
    "            \n",
    "            next_page = response.css('li.pager-next_last a::attr(href)').get()\n",
    "            \n",
    "            if next_page is not None:\n",
    "                next_page = response.urljoin(next_page)\n",
    "                yield scrapy.Request(next_page, callback = self.parse)\n",
    "\n",
    "                #现在面临的困惑在于，如果上述代码成功，还不能点击进入链接并获取文章内容\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#尝试在上文的基础中加入item并且为SQL格式输出打标\n",
    "from scrapy.item import Item, Field\n",
    "\n",
    "class EVitems (Item):\n",
    "    title = 'title'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://towardsdatascience.com/how-to-scrape-the-web-using-python-with-scrapy-spiders-e2328ac4526 \n",
    "\n",
    "    #an example based on Medium\n",
    "https://github.com/AiswaryaSrinivas/Scraping-Medium-and-Data-Analysis/blob/master/medium_scrapper_post.py\n",
    "    \n",
    "    #一种比较愚蠢的方式，就是直接搜集标题\n",
    "https://zhuanlan.zhihu.com/p/24769534 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
